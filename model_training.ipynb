{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c997f01-0229-41dd-b2d1-47a7789105de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Torch: 2.9.0+cpu\n",
      "CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"‚úÖ Torch:\", torch.__version__)\n",
    "print(\"CUDA –¥–æ—Å—Ç—É–ø–µ–Ω:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97bd0ed-f3a8-4e26-9140-d9764963e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: 359\n",
      "\n",
      "–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n",
      "   split                                               path   label\n",
      "0  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "1  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "2  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "3  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "4  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "\n",
      "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã: ['benign' 'malignant' 'normal']\n",
      "–†–∞–∑–±–∏–µ–Ω–∏—è (train/val/test):\n",
      "split\n",
      "train         126\n",
      "test          123\n",
      "validation    110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# –ü—É—Ç–∏\n",
    "PROJECT_ROOT = Path(r\"E:\\work\\mvp_ultrasound\")\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"dataset_index.csv\"\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫:\", len(df))\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã:\", df['label'].unique())\n",
    "print(\"–†–∞–∑–±–∏–µ–Ω–∏—è (train/val/test):\")\n",
    "print(df['split'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a4e0f3-45ac-420a-a969-4f0ac09d273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫\n",
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def _init_(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"path\"]\n",
    "        label = label2id[row[\"label\"]]\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        \n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PIL –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å torchvision.transforms\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        \n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e96fa6-36b1-4237-8a7b-8a1256301fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UltrasoundDataset() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m val_transforms = transforms.Compose([\n\u001b[32m     14\u001b[39m     transforms.ToTensor()\n\u001b[32m     15\u001b[39m ])\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m train_dataset = \u001b[43mUltrasoundDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m val_dataset = UltrasoundDataset(df_val, transform=val_transforms)\n\u001b[32m     20\u001b[39m test_dataset = UltrasoundDataset(df_test, transform=val_transforms)\n",
      "\u001b[31mTypeError\u001b[39m: UltrasoundDataset() takes no arguments"
     ]
    }
   ],
   "source": [
    "# –†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ\n",
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "train_dataset = UltrasoundDataset(df_train, transform=train_transforms)\n",
    "val_dataset = UltrasoundDataset(df_val, transform=val_transforms)\n",
    "test_dataset = UltrasoundDataset(df_test, transform=val_transforms)\n",
    "\n",
    "# DataLoader‚Äô—ã\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ DataLoaders —Å–æ–∑–¥–∞–Ω—ã\")\n",
    "print(\"–†–∞–∑–º–µ—Ä—ã:\")\n",
    "print(\"train:\", len(train_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(\"validation:\", len(val_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(\"test:\", len(test_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dac9eb4-c26d-4c3b-adae-63644e2d16d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (591619184.py, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É:\", e)`\u001b[39m\n                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"–û–±—ä–µ–∫—Ç:\", UltrasoundDataset)\n",
    "print(\"–¢–∏–ø:\", type(UltrasoundDataset))\n",
    "\n",
    "# –ü–æ–ø—Ä–æ–±—É–µ–º —É–∑–Ω–∞—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É _init_\n",
    "try:\n",
    "    print(\"–°–∏–≥–Ω–∞—Ç—É—Ä–∞ _init:\", inspect.signature(UltrasoundDataset.init_))\n",
    "except Exception as e:\n",
    "    print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É:\", e)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c80237-3232-410d-9b99-2f3edd08a354",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3970848764.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m`import inspect\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "`import inspect\n",
    "\n",
    "print(\"–û–±—ä–µ–∫—Ç:\", UltrasoundDataset)\n",
    "print(\"–¢–∏–ø:\", type(UltrasoundDataset))\n",
    "\n",
    "# –ü–æ–ø—Ä–æ–±—É–µ–º —É–∑–Ω–∞—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É _init_\n",
    "try:\n",
    "    print(\"–°–∏–≥–Ω–∞—Ç—É—Ä–∞ _init:\", inspect.signature(UltrasoundDataset.init_))\n",
    "except Exception as e:\n",
    "    print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6f23a2-6346-4534-bac1-5d5d559eee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—ä–µ–∫—Ç: <class '__main__.UltrasoundDataset'>\n",
      "–¢–∏–ø: <class 'type'>\n",
      "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É: type object 'UltrasoundDataset' has no attribute 'init_'\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"–û–±—ä–µ–∫—Ç:\", UltrasoundDataset)\n",
    "print(\"–¢–∏–ø:\", type(UltrasoundDataset))\n",
    "\n",
    "# –ü–æ–ø—Ä–æ–±—É–µ–º —É–∑–Ω–∞—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É _init_\n",
    "try:\n",
    "    print(\"–°–∏–≥–Ω–∞—Ç—É—Ä–∞ _init:\", inspect.signature(UltrasoundDataset.init_))\n",
    "except Exception as e:\n",
    "    print(\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞—Ç—É—Ä—É:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec64afc9-ef1e-4cc9-9206-d7d8f0100167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDatasetV2(Dataset):\n",
    "    def _init_(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"path\"]\n",
    "        label = label2id[row[\"label\"]]\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3540dd-2d96-4039-9bc1-7a910d94ffd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UltrasoundDatasetV2() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     16\u001b[39m val_transforms = transforms.Compose([\n\u001b[32m     17\u001b[39m     transforms.ToTensor()\n\u001b[32m     18\u001b[39m ])\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –ù–û–í–´–ú –∫–ª–∞—Å—Å–æ–º\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m train_dataset = \u001b[43mUltrasoundDatasetV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m val_dataset = UltrasoundDatasetV2(df_val, transform=val_transforms)\n\u001b[32m     23\u001b[39m test_dataset = UltrasoundDatasetV2(df_test, transform=val_transforms)\n",
      "\u001b[31mTypeError\u001b[39m: UltrasoundDatasetV2() takes no arguments"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –ù–û–í–´–ú –∫–ª–∞—Å—Å–æ–º\n",
    "train_dataset = UltrasoundDatasetV2(df_train, transform=train_transforms)\n",
    "val_dataset = UltrasoundDatasetV2(df_val, transform=val_transforms)\n",
    "test_dataset = UltrasoundDatasetV2(df_test, transform=val_transforms)\n",
    "\n",
    "# DataLoader‚Äô—ã\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ DataLoaders —Å–æ–∑–¥–∞–Ω—ã\")\n",
    "print(\"train:\", len(train_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(\"validation:\", len(val_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(\"test:\", len(test_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97d2d04-7d45-4bc0-86c2-73cd8d6f27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Torch: 2.9.0+cpu\n",
      "CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(\"‚úÖ Torch:\", torch.__version__)\n",
    "print(\"CUDA –¥–æ—Å—Ç—É–ø–µ–Ω:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2142b58c-9bc7-4830-abc0-4dd4ed79d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: 359\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(r\"E:\\work\\mvp_ultrasound\")\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"dataset_index.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80a27db-91ee-421c-acc2-d2ffa199f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDatasetFresh(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"path\"]\n",
    "        label = label2id[row[\"label\"]]\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18c7ebf-f60e-482d-bd24-943cc93e42da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DataLoaders —Å–æ–∑–¥–∞–Ω—ã\n",
      "train: 126 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "validation: 110 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "test: 123 –ø—Ä–∏–º–µ—Ä–æ–≤\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = UltrasoundDatasetFresh(df_train, transform=train_transforms)\n",
    "val_dataset = UltrasoundDatasetFresh(df_val, transform=val_transforms)\n",
    "test_dataset = UltrasoundDatasetFresh(df_test, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ DataLoaders —Å–æ–∑–¥–∞–Ω—ã\")\n",
    "print(\"train:\", len(train_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(\"validation:\", len(val_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(\"test:\", len(test_dataset), \"–ø—Ä–∏–º–µ—Ä–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632d810c-c2a2-4e7d-8057-54753f7af52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# --- –ë–∞–∑–æ–≤–∞—è U-Net —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä ---\n",
    "class UNetBlock(nn.Module):\n",
    "    def _init_(self, in_ch, out_ch):\n",
    "        super()._init_()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class HybridUNetClassifier(nn.Module):\n",
    "    def _init_(self, num_classes=3):\n",
    "        super()._init_()\n",
    "        # U-Net encoder\n",
    "        self.enc1 = UNetBlock(1, 32)\n",
    "        self.enc2 = UNetBlock(32, 64)\n",
    "        self.enc3 = UNetBlock(64, 128)\n",
    "\n",
    "        # Down-sampling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = UNetBlock(128, 64)\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = UNetBlock(64, 32)\n",
    "\n",
    "        # Output segmentation map\n",
    "        self.seg_head = nn.Conv2d(32, 1, kernel_size=1)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "\n",
    "        # Decoder (for segmentation)\n",
    "        x_up1 = self.up1(x3)\n",
    "        x_cat1 = torch.cat([x_up1, x2], dim=1)\n",
    "        x_dec1 = self.dec1(x_cat1)\n",
    "        x_up2 = self.up2(x_dec1)\n",
    "        x_cat2 = torch.cat([x_up2, x1], dim=1)\n",
    "        x_dec2 = self.dec2(x_cat2)\n",
    "\n",
    "        seg_output = torch.sigmoid(self.seg_head(x_dec2))  # segmentation output\n",
    "\n",
    "        # Classification (from the deepest encoder feature)\n",
    "        cls_logits = self.classifier(x3)\n",
    "\n",
    "        return seg_output, cls_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d87bc0b-69c1-4692-8036-6903fdecdf65",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HybridUNetClassifier.__init__() got an unexpected keyword argument 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# —É –Ω–∞—Å CPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mHybridUNetClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# –≤–æ–∑—å–º—ë–º –æ–¥–∏–Ω –±–∞—Ç—á –∏–∑ train_loader\u001b[39;00m\n\u001b[32m      5\u001b[39m xb, yb = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))  \u001b[38;5;66;03m# xb: [B, 1, 256, 256], yb: [B]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Miniconda3\\envs\\mvp-ultra\\Lib\\site-packages\\torch\\nn\\modules\\module.py:485\u001b[39m, in \u001b[36mModule.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Backward compatibility: no args used to be allowed when call_super_init=False\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    486\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() got an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    492\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: HybridUNetClassifier.__init__() got an unexpected keyword argument 'num_classes'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")  # —É –Ω–∞—Å CPU\n",
    "model = HybridUNetClassifier(num_classes=3).to(device)\n",
    "\n",
    "# –≤–æ–∑—å–º—ë–º –æ–¥–∏–Ω –±–∞—Ç—á –∏–∑ train_loader\n",
    "xb, yb = next(iter(train_loader))  # xb: [B, 1, 256, 256], yb: [B]\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "seg_out, cls_logits = model(xb)\n",
    "print(\"–§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞:\", xb.shape)\n",
    "print(\"–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (seg_out):\", seg_out.shape, \"–¥–∏–∞–ø–∞–∑–æ–Ω:\", (seg_out.min().item(), seg_out.max().item()))\n",
    "print(\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (cls_logits):\", cls_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb963d38-7e99-47ad-b5ce-fa3e52606e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNetBlockV2(nn.Module):\n",
    "    def _init_(self, in_ch, out_ch):\n",
    "        super()._init_()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class HybridUNetClassifierV2(nn.Module):\n",
    "    def _init_(self, num_classes=3):\n",
    "        super()._init_()\n",
    "        # Encoder\n",
    "        self.enc1 = UNetBlockV2(1, 32)\n",
    "        self.enc2 = UNetBlockV2(32, 64)\n",
    "        self.enc3 = UNetBlockV2(64, 128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = UNetBlockV2(128, 64)\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = UNetBlockV2(64, 32)\n",
    "\n",
    "        # Heads\n",
    "        self.seg_head = nn.Conv2d(32, 1, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "\n",
    "        # Decoder (for segmentation)\n",
    "        x_up1 = self.up1(x3)\n",
    "        x_cat1 = torch.cat([x_up1, x2], dim=1)\n",
    "        x_dec1 = self.dec1(x_cat1)\n",
    "        x_up2 = self.up2(x_dec1)\n",
    "        x_cat2 = torch.cat([x_up2, x1], dim=1)\n",
    "        x_dec2 = self.dec2(x_cat2)\n",
    "\n",
    "        seg_output = torch.sigmoid(self.seg_head(x_dec2))\n",
    "        cls_logits = self.classifier(x3)\n",
    "\n",
    "        return seg_output, cls_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51aefab-b7e6-4e3d-a3c6-7cd2b18e9e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HybridUNetClassifierV2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mHybridUNetClassifierV2\u001b[49m(num_classes=\u001b[32m3\u001b[39m).to(device)\n\u001b[32m      4\u001b[39m xb, yb = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[32m      5\u001b[39m xb, yb = xb.to(device), yb.to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'HybridUNetClassifierV2' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = HybridUNetClassifierV2(num_classes=3).to(device)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "seg_out, cls_logits = model(xb)\n",
    "\n",
    "print(\"–§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞:\", xb.shape)\n",
    "print(\"–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (seg_out):\", seg_out.shape)\n",
    "print(\"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (cls_logits):\", cls_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144b280b-3f0e-4af7-b1c1-bc7b50f461f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Torch: 2.9.0+cpu\n",
      "CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"‚úÖ Torch:\", torch.__version__)\n",
    "print(\"CUDA –¥–æ—Å—Ç—É–ø–µ–Ω:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b355d5a-d355-4314-b704-ec500fe53f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: 359\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(r\"E:\\work\\mvp_ultrasound\")\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"dataset_index.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f608fc3-9157-4219-ac7b-b32b5f1b9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDatasetFresh(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row[\"path\"], cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img) if self.transform else transforms.ToTensor()(img)\n",
    "        label = torch.tensor(label2id[row[\"label\"]], dtype=torch.long)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd50c8dc-67f4-43b5-b1bc-73f00c3796d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_train = \u001b[43mdf\u001b[49m[df[\u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m df_val = df[df[\u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m df_test = df[df[\u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_tf = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_loader = DataLoader(UltrasoundDatasetFresh(df_train, train_tf), batch_size=8, shuffle=True)\n",
    "val_loader   = DataLoader(UltrasoundDatasetFresh(df_val, val_tf),   batch_size=8, shuffle=False)\n",
    "test_loader  = DataLoader(UltrasoundDatasetFresh(df_test, val_tf),  batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ DataLoaders –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c952dc-d306-4f11-a4bc-e4969ea9ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBlockNew(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class HybridUNetClassifierClean(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = UNetBlockNew(1, 32)\n",
    "        self.enc2 = UNetBlockNew(32, 64)\n",
    "        self.enc3 = UNetBlockNew(64, 128)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up1  = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = UNetBlockNew(128, 64)\n",
    "        self.up2  = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = UNetBlockNew(64, 32)\n",
    "        self.seg_head = nn.Conv2d(32, 1, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x_up1 = self.up1(x3)\n",
    "        x_dec1 = self.dec1(torch.cat([x_up1, x2], 1))\n",
    "        x_up2 = self.up2(x_dec1)\n",
    "        x_dec2 = self.dec2(torch.cat([x_up2, x1], 1))\n",
    "        seg = torch.sigmoid(self.seg_head(x_dec2))\n",
    "        cls = self.classifier(x3)\n",
    "        return seg, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bf92e1-fab8-4a38-be5e-28b054bf0f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model = HybridUNetClassifierClean(num_classes=\u001b[32m3\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m xb, yb = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_loader\u001b[49m))\n\u001b[32m      4\u001b[39m seg, \u001b[38;5;28mcls\u001b[39m = model(xb)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mseg:\u001b[39m\u001b[33m\"\u001b[39m, seg.shape, \u001b[33m\"\u001b[39m\u001b[33mcls:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = HybridUNetClassifierClean(num_classes=3).to(device)\n",
    "xb, yb = next(iter(train_loader))\n",
    "seg, cls = model(xb)\n",
    "print(\"seg:\", seg.shape, \"cls:\", cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42050b0-503e-4d49-aa17-ce47532a9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ª–æ—Å—Å –≥–æ—Ç–æ–≤—ã\n"
     ]
    }
   ],
   "source": [
    "# –õ–æ—Å—Å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (CrossEntropy)\n",
    "cls_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# –ü–æ–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–µ –æ–±—É—á–∞–µ–º (–Ω–µ—Ç –º–∞—Å–æ–∫)\n",
    "# –ù–æ –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å seg_loss = 0, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ –ª–æ–º–∞–ª–∞—Å—å –ø—Ä–∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏\n",
    "def total_loss(cls_logits, y_true):\n",
    "    cls_loss = cls_criterion(cls_logits, y_true)\n",
    "    return cls_loss  # –ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "\n",
    "# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "print(\"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ª–æ—Å—Å –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027d2fdd-9fca-4db7-9c2c-c771faba420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –§—É–Ω–∫—Ü–∏–∏ evaluate() –∏ accuracy() –≥–æ—Ç–æ–≤—ã\n"
     ]
    }
   ],
   "source": [
    "def accuracy(logits, y_true):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == y_true).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        seg_out, cls_logits = model(xb)\n",
    "        loss = cls_criterion(cls_logits, yb)\n",
    "        acc = accuracy(cls_logits, yb)\n",
    "        bs = yb.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc += acc * bs\n",
    "        total_n += bs\n",
    "    return total_loss / total_n, total_acc / total_n\n",
    "\n",
    "print(\"‚úÖ –§—É–Ω–∫—Ü–∏–∏ evaluate() –∏ accuracy() –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435ac9ee-2a22-4c19-8baa-c78b8113ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train_loss=1.1266, acc=0.341 | val_loss=1.0714, acc=0.373\n",
      "[2/3] train_loss=1.0258, acc=0.381 | val_loss=1.5027, acc=0.391\n",
      "[3/3] train_loss=1.0068, acc=0.373 | val_loss=1.4176, acc=0.391\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss, running_acc, seen = 0.0, 0.0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        seg_out, cls_logits = model(xb)\n",
    "        loss = total_loss(cls_logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(cls_logits, yb)\n",
    "        bs = yb.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        running_acc += acc * bs\n",
    "        seen += bs\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc = running_acc / seen\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    print(f\"[{epoch}/{EPOCHS}] \"\n",
    "          f\"train_loss={train_loss:.4f}, acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.4f}, acc={val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2b0bcc-1af6-4f53-9857-fd4e3a6f218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# –°—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–ª—è grayscale-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "mean_gray = [0.5]\n",
    "std_gray = [0.5]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_gray, std=std_gray)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_gray, std=std_gray)\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(UltrasoundDatasetFresh(df_train, transform=train_transforms), batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(UltrasoundDatasetFresh(df_val, transform=val_transforms), batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def56ff5-7f3d-43ec-bd79-d533899ffa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ train: Counter({'benign': 50, 'normal': 50, 'malignant': 26})\n",
      "‚öñÔ∏è –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: tensor([2.5200, 4.8462, 2.5200])\n",
      "‚úÖ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –ª–æ—Å—Å\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# –ü–æ–¥—Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "class_counts = Counter(df_train[\"label\"])\n",
    "print(\"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ train:\", class_counts)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≤–µ—Å–∞ (–º–µ–Ω—å—à–µ –ø—Ä–∏–º–µ—Ä–æ–≤ = –±–æ–ª—å—à–∏–π –≤–µ—Å)\n",
    "total = sum(class_counts.values())\n",
    "class_weights = [total / class_counts[l] for l in [\"benign\", \"malignant\", \"normal\"]]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "print(\"‚öñÔ∏è –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤:\", class_weights)\n",
    "\n",
    "# –ù–æ–≤—ã–π –ª–æ—Å—Å —Å —É—á–µ—Ç–æ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞\n",
    "cls_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(\"‚úÖ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –ª–æ—Å—Å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ba5ab9-5f03-4079-bd68-95deb6b2c338",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m optimizer = optim.AdamW(model.parameters(), lr=\u001b[32m1e-3\u001b[39m, weight_decay=\u001b[32m1e-4\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Scheduler: —É–º–µ–Ω—å—à–∞–µ—Ç LR –≤ 2 —Ä–∞–∑–∞, –µ—Å–ª–∏ 2 —ç–ø–æ—Ö–∏ –ø–æ–¥—Ä—è–¥ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m scheduler = \u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Scheduler –¥–æ–±–∞–≤–ª–µ–Ω (ReduceLROnPlateau)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler: —É–º–µ–Ω—å—à–∞–µ—Ç LR –≤ 2 —Ä–∞–∑–∞, –µ—Å–ª–∏ 2 —ç–ø–æ—Ö–∏ –ø–æ–¥—Ä—è–¥ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "print(\"‚úÖ Scheduler –¥–æ–±–∞–≤–ª–µ–Ω (ReduceLROnPlateau)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba3d1c7-1de0-47ae-a2d5-ce6697f86d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scheduler –¥–æ–±–∞–≤–ª–µ–Ω (ReduceLROnPlateau, —Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è –≤–µ—Ä—Å–∏—è)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –±–µ–∑ verbose\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "print(\"‚úÖ Scheduler –¥–æ–±–∞–≤–ª–µ–Ω (ReduceLROnPlateau, —Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è –≤–µ—Ä—Å–∏—è)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659ce4c2-76d8-44c0-ba13-557aab9ce7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] train_loss=1.0273, acc=0.373 | val_loss=1.0966, acc=0.418 | lr=0.001000\n",
      "[2/5] train_loss=0.9628, acc=0.437 | val_loss=1.0389, acc=0.491 | lr=0.001000\n",
      "[3/5] train_loss=0.9599, acc=0.373 | val_loss=1.0888, acc=0.482 | lr=0.001000\n",
      "[4/5] train_loss=0.9470, acc=0.500 | val_loss=1.1519, acc=0.373 | lr=0.001000\n",
      "[5/5] train_loss=0.9615, acc=0.444 | val_loss=1.3215, acc=0.245 | lr=0.000500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss, running_acc, seen = 0.0, 0.0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        seg_out, cls_logits = model(xb)\n",
    "        loss = total_loss(cls_logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(cls_logits, yb)\n",
    "        bs = yb.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        running_acc += acc * bs\n",
    "        seen += bs\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc = running_acc / seen\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    # –æ–±–Ω–æ–≤–ª—è–µ–º scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"[{epoch}/{EPOCHS}] \"\n",
    "          f\"train_loss={train_loss:.4f}, acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.4f}, acc={val_acc:.3f} | \"\n",
    "          f\"lr={optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f78287e-936e-4789-96f1-3a94662ad85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: E:\\work\\mvp_ultrasound\\models\\mvp_model.pt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "models_dir = Path(r\"E:\\work\\mvp_ultrasound\\models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "save_path = models_dir / \"mvp_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01598d8b-34c8-41d9-9fbd-aed47f367389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
