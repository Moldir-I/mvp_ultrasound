{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c997f01-0229-41dd-b2d1-47a7789105de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Torch: 2.9.0+cpu\n",
      "CUDA доступен: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✅ Torch:\", torch.__version__)\n",
    "print(\"CUDA доступен:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97bd0ed-f3a8-4e26-9140-d9764963e547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк: 359\n",
      "\n",
      "Первые 5 строк:\n",
      "   split                                               path   label\n",
      "0  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "1  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "2  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "3  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "4  train  E:\\work\\mvp_ultrasound\\data\\processed\\train\\be...  benign\n",
      "\n",
      "Уникальные классы: ['benign' 'malignant' 'normal']\n",
      "Разбиения (train/val/test):\n",
      "split\n",
      "train         126\n",
      "test          123\n",
      "validation    110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Пути\n",
    "PROJECT_ROOT = Path(r\"E:\\work\\mvp_ultrasound\")\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"dataset_index.csv\"\n",
    "\n",
    "# Загружаем CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(\"Всего строк:\", len(df))\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nУникальные классы:\", df['label'].unique())\n",
    "print(\"Разбиения (train/val/test):\")\n",
    "print(df['split'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a4e0f3-45ac-420a-a969-4f0ac09d273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Словарь для кодирования меток\n",
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def _init_(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"path\"]\n",
    "        label = label2id[row[\"label\"]]\n",
    "        \n",
    "        # Загружаем изображение\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        \n",
    "        # Преобразуем в PIL для совместимости с torchvision.transforms\n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        \n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e96fa6-36b1-4237-8a7b-8a1256301fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UltrasoundDataset() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     13\u001b[39m val_transforms = transforms.Compose([\n\u001b[32m     14\u001b[39m     transforms.ToTensor()\n\u001b[32m     15\u001b[39m ])\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Создаём датасеты\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m train_dataset = \u001b[43mUltrasoundDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m val_dataset = UltrasoundDataset(df_val, transform=val_transforms)\n\u001b[32m     20\u001b[39m test_dataset = UltrasoundDataset(df_test, transform=val_transforms)\n",
      "\u001b[31mTypeError\u001b[39m: UltrasoundDataset() takes no arguments"
     ]
    }
   ],
   "source": [
    "# Разделим данные\n",
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "# Преобразования (аугментации)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Создаём датасеты\n",
    "train_dataset = UltrasoundDataset(df_train, transform=train_transforms)\n",
    "val_dataset = UltrasoundDataset(df_val, transform=val_transforms)\n",
    "test_dataset = UltrasoundDataset(df_test, transform=val_transforms)\n",
    "\n",
    "# DataLoader’ы\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"✅ DataLoaders созданы\")\n",
    "print(\"Размеры:\")\n",
    "print(\"train:\", len(train_dataset), \"примеров\")\n",
    "print(\"validation:\", len(val_dataset), \"примеров\")\n",
    "print(\"test:\", len(test_dataset), \"примеров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dac9eb4-c26d-4c3b-adae-63644e2d16d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (591619184.py, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"Не удалось получить сигнатуру:\", e)`\u001b[39m\n                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"Объект:\", UltrasoundDataset)\n",
    "print(\"Тип:\", type(UltrasoundDataset))\n",
    "\n",
    "# Попробуем узнать сигнатуру _init_\n",
    "try:\n",
    "    print(\"Сигнатура _init:\", inspect.signature(UltrasoundDataset.init_))\n",
    "except Exception as e:\n",
    "    print(\"Не удалось получить сигнатуру:\", e)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c80237-3232-410d-9b99-2f3edd08a354",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3970848764.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m`import inspect\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "`import inspect\n",
    "\n",
    "print(\"Объект:\", UltrasoundDataset)\n",
    "print(\"Тип:\", type(UltrasoundDataset))\n",
    "\n",
    "# Попробуем узнать сигнатуру _init_\n",
    "try:\n",
    "    print(\"Сигнатура _init:\", inspect.signature(UltrasoundDataset.init_))\n",
    "except Exception as e:\n",
    "    print(\"Не удалось получить сигнатуру:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6f23a2-6346-4534-bac1-5d5d559eee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объект: <class '__main__.UltrasoundDataset'>\n",
      "Тип: <class 'type'>\n",
      "Не удалось получить сигнатуру: type object 'UltrasoundDataset' has no attribute 'init_'\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(\"Объект:\", UltrasoundDataset)\n",
    "print(\"Тип:\", type(UltrasoundDataset))\n",
    "\n",
    "# Попробуем узнать сигнатуру _init_\n",
    "try:\n",
    "    print(\"Сигнатура _init:\", inspect.signature(UltrasoundDataset.init_))\n",
    "except Exception as e:\n",
    "    print(\"Не удалось получить сигнатуру:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec64afc9-ef1e-4cc9-9206-d7d8f0100167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDatasetV2(Dataset):\n",
    "    def _init_(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"path\"]\n",
    "        label = label2id[row[\"label\"]]\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3540dd-2d96-4039-9bc1-7a910d94ffd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UltrasoundDatasetV2() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     16\u001b[39m val_transforms = transforms.Compose([\n\u001b[32m     17\u001b[39m     transforms.ToTensor()\n\u001b[32m     18\u001b[39m ])\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Создаём датасеты с НОВЫМ классом\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m train_dataset = \u001b[43mUltrasoundDatasetV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m val_dataset = UltrasoundDatasetV2(df_val, transform=val_transforms)\n\u001b[32m     23\u001b[39m test_dataset = UltrasoundDatasetV2(df_test, transform=val_transforms)\n",
      "\u001b[31mTypeError\u001b[39m: UltrasoundDatasetV2() takes no arguments"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Разделяем данные\n",
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "# Преобразования (аугментации)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Создаём датасеты с НОВЫМ классом\n",
    "train_dataset = UltrasoundDatasetV2(df_train, transform=train_transforms)\n",
    "val_dataset = UltrasoundDatasetV2(df_val, transform=val_transforms)\n",
    "test_dataset = UltrasoundDatasetV2(df_test, transform=val_transforms)\n",
    "\n",
    "# DataLoader’ы\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"✅ DataLoaders созданы\")\n",
    "print(\"train:\", len(train_dataset), \"примеров\")\n",
    "print(\"validation:\", len(val_dataset), \"примеров\")\n",
    "print(\"test:\", len(test_dataset), \"примеров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97d2d04-7d45-4bc0-86c2-73cd8d6f27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Torch: 2.9.0+cpu\n",
      "CUDA доступен: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(\"✅ Torch:\", torch.__version__)\n",
    "print(\"CUDA доступен:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2142b58c-9bc7-4830-abc0-4dd4ed79d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк: 359\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(r\"E:\\work\\mvp_ultrasound\")\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"dataset_index.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Всего строк:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80a27db-91ee-421c-acc2-d2ffa199f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDatasetFresh(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row[\"path\"]\n",
    "        label = label2id[row[\"label\"]]\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18c7ebf-f60e-482d-bd24-943cc93e42da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataLoaders созданы\n",
      "train: 126 примеров\n",
      "validation: 110 примеров\n",
      "test: 123 примеров\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = UltrasoundDatasetFresh(df_train, transform=train_transforms)\n",
    "val_dataset = UltrasoundDatasetFresh(df_val, transform=val_transforms)\n",
    "test_dataset = UltrasoundDatasetFresh(df_test, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"✅ DataLoaders созданы\")\n",
    "print(\"train:\", len(train_dataset), \"примеров\")\n",
    "print(\"validation:\", len(val_dataset), \"примеров\")\n",
    "print(\"test:\", len(test_dataset), \"примеров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632d810c-c2a2-4e7d-8057-54753f7af52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Базовая U-Net энкодер-декодер ---\n",
    "class UNetBlock(nn.Module):\n",
    "    def _init_(self, in_ch, out_ch):\n",
    "        super()._init_()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class HybridUNetClassifier(nn.Module):\n",
    "    def _init_(self, num_classes=3):\n",
    "        super()._init_()\n",
    "        # U-Net encoder\n",
    "        self.enc1 = UNetBlock(1, 32)\n",
    "        self.enc2 = UNetBlock(32, 64)\n",
    "        self.enc3 = UNetBlock(64, 128)\n",
    "\n",
    "        # Down-sampling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = UNetBlock(128, 64)\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = UNetBlock(64, 32)\n",
    "\n",
    "        # Output segmentation map\n",
    "        self.seg_head = nn.Conv2d(32, 1, kernel_size=1)\n",
    "\n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "\n",
    "        # Decoder (for segmentation)\n",
    "        x_up1 = self.up1(x3)\n",
    "        x_cat1 = torch.cat([x_up1, x2], dim=1)\n",
    "        x_dec1 = self.dec1(x_cat1)\n",
    "        x_up2 = self.up2(x_dec1)\n",
    "        x_cat2 = torch.cat([x_up2, x1], dim=1)\n",
    "        x_dec2 = self.dec2(x_cat2)\n",
    "\n",
    "        seg_output = torch.sigmoid(self.seg_head(x_dec2))  # segmentation output\n",
    "\n",
    "        # Classification (from the deepest encoder feature)\n",
    "        cls_logits = self.classifier(x3)\n",
    "\n",
    "        return seg_output, cls_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d87bc0b-69c1-4692-8036-6903fdecdf65",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HybridUNetClassifier.__init__() got an unexpected keyword argument 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# у нас CPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mHybridUNetClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# возьмём один батч из train_loader\u001b[39;00m\n\u001b[32m      5\u001b[39m xb, yb = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))  \u001b[38;5;66;03m# xb: [B, 1, 256, 256], yb: [B]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Miniconda3\\envs\\mvp-ultra\\Lib\\site-packages\\torch\\nn\\modules\\module.py:485\u001b[39m, in \u001b[36mModule.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# Backward compatibility: no args used to be allowed when call_super_init=False\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    486\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() got an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    488\u001b[39m     )\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    492\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m were\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: HybridUNetClassifier.__init__() got an unexpected keyword argument 'num_classes'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")  # у нас CPU\n",
    "model = HybridUNetClassifier(num_classes=3).to(device)\n",
    "\n",
    "# возьмём один батч из train_loader\n",
    "xb, yb = next(iter(train_loader))  # xb: [B, 1, 256, 256], yb: [B]\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "seg_out, cls_logits = model(xb)\n",
    "print(\"Форма входа:\", xb.shape)\n",
    "print(\"Сегментация (seg_out):\", seg_out.shape, \"диапазон:\", (seg_out.min().item(), seg_out.max().item()))\n",
    "print(\"Классификация (cls_logits):\", cls_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb963d38-7e99-47ad-b5ce-fa3e52606e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNetBlockV2(nn.Module):\n",
    "    def _init_(self, in_ch, out_ch):\n",
    "        super()._init_()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class HybridUNetClassifierV2(nn.Module):\n",
    "    def _init_(self, num_classes=3):\n",
    "        super()._init_()\n",
    "        # Encoder\n",
    "        self.enc1 = UNetBlockV2(1, 32)\n",
    "        self.enc2 = UNetBlockV2(32, 64)\n",
    "        self.enc3 = UNetBlockV2(64, 128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = UNetBlockV2(128, 64)\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = UNetBlockV2(64, 32)\n",
    "\n",
    "        # Heads\n",
    "        self.seg_head = nn.Conv2d(32, 1, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "\n",
    "        # Decoder (for segmentation)\n",
    "        x_up1 = self.up1(x3)\n",
    "        x_cat1 = torch.cat([x_up1, x2], dim=1)\n",
    "        x_dec1 = self.dec1(x_cat1)\n",
    "        x_up2 = self.up2(x_dec1)\n",
    "        x_cat2 = torch.cat([x_up2, x1], dim=1)\n",
    "        x_dec2 = self.dec2(x_cat2)\n",
    "\n",
    "        seg_output = torch.sigmoid(self.seg_head(x_dec2))\n",
    "        cls_logits = self.classifier(x3)\n",
    "\n",
    "        return seg_output, cls_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51aefab-b7e6-4e3d-a3c6-7cd2b18e9e03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HybridUNetClassifierV2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mHybridUNetClassifierV2\u001b[49m(num_classes=\u001b[32m3\u001b[39m).to(device)\n\u001b[32m      4\u001b[39m xb, yb = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[32m      5\u001b[39m xb, yb = xb.to(device), yb.to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'HybridUNetClassifierV2' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = HybridUNetClassifierV2(num_classes=3).to(device)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "seg_out, cls_logits = model(xb)\n",
    "\n",
    "print(\"Форма входа:\", xb.shape)\n",
    "print(\"Сегментация (seg_out):\", seg_out.shape)\n",
    "print(\"Классификация (cls_logits):\", cls_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144b280b-3f0e-4af7-b1c1-bc7b50f461f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Torch: 2.9.0+cpu\n",
      "CUDA доступен: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✅ Torch:\", torch.__version__)\n",
    "print(\"CUDA доступен:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b355d5a-d355-4314-b704-ec500fe53f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего строк: 359\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(r\"E:\\work\\mvp_ultrasound\")\n",
    "CSV_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"dataset_index.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Всего строк:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f608fc3-9157-4219-ac7b-b32b5f1b9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"benign\": 0, \"malignant\": 1, \"normal\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "class UltrasoundDatasetFresh(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row[\"path\"], cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img) if self.transform else transforms.ToTensor()(img)\n",
    "        label = torch.tensor(label2id[row[\"label\"]], dtype=torch.long)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd50c8dc-67f4-43b5-b1bc-73f00c3796d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_train = \u001b[43mdf\u001b[49m[df[\u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m df_val = df[df[\u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m df_test = df[df[\u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"validation\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_tf = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_loader = DataLoader(UltrasoundDatasetFresh(df_train, train_tf), batch_size=8, shuffle=True)\n",
    "val_loader   = DataLoader(UltrasoundDatasetFresh(df_val, val_tf),   batch_size=8, shuffle=False)\n",
    "test_loader  = DataLoader(UltrasoundDatasetFresh(df_test, val_tf),  batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"✅ DataLoaders готовы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c952dc-d306-4f11-a4bc-e4969ea9ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBlockNew(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class HybridUNetClassifierClean(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.enc1 = UNetBlockNew(1, 32)\n",
    "        self.enc2 = UNetBlockNew(32, 64)\n",
    "        self.enc3 = UNetBlockNew(64, 128)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up1  = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = UNetBlockNew(128, 64)\n",
    "        self.up2  = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = UNetBlockNew(64, 32)\n",
    "        self.seg_head = nn.Conv2d(32, 1, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x_up1 = self.up1(x3)\n",
    "        x_dec1 = self.dec1(torch.cat([x_up1, x2], 1))\n",
    "        x_up2 = self.up2(x_dec1)\n",
    "        x_dec2 = self.dec2(torch.cat([x_up2, x1], 1))\n",
    "        seg = torch.sigmoid(self.seg_head(x_dec2))\n",
    "        cls = self.classifier(x3)\n",
    "        return seg, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bf92e1-fab8-4a38-be5e-28b054bf0f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model = HybridUNetClassifierClean(num_classes=\u001b[32m3\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m xb, yb = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_loader\u001b[49m))\n\u001b[32m      4\u001b[39m seg, \u001b[38;5;28mcls\u001b[39m = model(xb)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mseg:\u001b[39m\u001b[33m\"\u001b[39m, seg.shape, \u001b[33m\"\u001b[39m\u001b[33mcls:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = HybridUNetClassifierClean(num_classes=3).to(device)\n",
    "xb, yb = next(iter(train_loader))\n",
    "seg, cls = model(xb)\n",
    "print(\"seg:\", seg.shape, \"cls:\", cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42050b0-503e-4d49-aa17-ce47532a9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Оптимизатор и лосс готовы\n"
     ]
    }
   ],
   "source": [
    "# Лосс для классификации (CrossEntropy)\n",
    "cls_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Пока сегментацию не обучаем (нет масок)\n",
    "# Но можно считать seg_loss = 0, чтобы модель не ломалась при комбинировании\n",
    "def total_loss(cls_logits, y_true):\n",
    "    cls_loss = cls_criterion(cls_logits, y_true)\n",
    "    return cls_loss  # пока только классификация\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "print(\"✅ Оптимизатор и лосс готовы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027d2fdd-9fca-4db7-9c2c-c771faba420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Функции evaluate() и accuracy() готовы\n"
     ]
    }
   ],
   "source": [
    "def accuracy(logits, y_true):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == y_true).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_n = 0.0, 0.0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        seg_out, cls_logits = model(xb)\n",
    "        loss = cls_criterion(cls_logits, yb)\n",
    "        acc = accuracy(cls_logits, yb)\n",
    "        bs = yb.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc += acc * bs\n",
    "        total_n += bs\n",
    "    return total_loss / total_n, total_acc / total_n\n",
    "\n",
    "print(\"✅ Функции evaluate() и accuracy() готовы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "435ac9ee-2a22-4c19-8baa-c78b8113ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] train_loss=1.1266, acc=0.341 | val_loss=1.0714, acc=0.373\n",
      "[2/3] train_loss=1.0258, acc=0.381 | val_loss=1.5027, acc=0.391\n",
      "[3/3] train_loss=1.0068, acc=0.373 | val_loss=1.4176, acc=0.391\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss, running_acc, seen = 0.0, 0.0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        seg_out, cls_logits = model(xb)\n",
    "        loss = total_loss(cls_logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(cls_logits, yb)\n",
    "        bs = yb.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        running_acc += acc * bs\n",
    "        seen += bs\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc = running_acc / seen\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    print(f\"[{epoch}/{EPOCHS}] \"\n",
    "          f\"train_loss={train_loss:.4f}, acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.4f}, acc={val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2b0bcc-1af6-4f53-9857-fd4e3a6f218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Трансформации и нормализация обновлены\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Среднее и стандартное отклонение для grayscale-изображений\n",
    "mean_gray = [0.5]\n",
    "std_gray = [0.5]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_gray, std=std_gray)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_gray, std=std_gray)\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(UltrasoundDatasetFresh(df_train, transform=train_transforms), batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(UltrasoundDatasetFresh(df_val, transform=val_transforms), batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"✅ Трансформации и нормализация обновлены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def56ff5-7f3d-43ec-bd79-d533899ffa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Количество примеров в train: Counter({'benign': 50, 'normal': 50, 'malignant': 26})\n",
      "⚖️ Веса классов: tensor([2.5200, 4.8462, 2.5200])\n",
      "✅ Балансировка классов добавлена в лосс\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# Подсчитаем количество примеров каждого класса\n",
    "class_counts = Counter(df_train[\"label\"])\n",
    "print(\"📊 Количество примеров в train:\", class_counts)\n",
    "\n",
    "# Преобразуем в веса (меньше примеров = больший вес)\n",
    "total = sum(class_counts.values())\n",
    "class_weights = [total / class_counts[l] for l in [\"benign\", \"malignant\", \"normal\"]]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "print(\"⚖️ Веса классов:\", class_weights)\n",
    "\n",
    "# Новый лосс с учетом дисбаланса\n",
    "cls_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(\"✅ Балансировка классов добавлена в лосс\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ba5ab9-5f03-4079-bd68-95deb6b2c338",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m optimizer = optim.AdamW(model.parameters(), lr=\u001b[32m1e-3\u001b[39m, weight_decay=\u001b[32m1e-4\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Scheduler: уменьшает LR в 2 раза, если 2 эпохи подряд нет улучшения валидации\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m scheduler = \u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Scheduler добавлен (ReduceLROnPlateau)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler: уменьшает LR в 2 раза, если 2 эпохи подряд нет улучшения валидации\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "print(\"✅ Scheduler добавлен (ReduceLROnPlateau)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba3d1c7-1de0-47ae-a2d5-ce6697f86d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scheduler добавлен (ReduceLROnPlateau, совместимая версия)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Упрощённый вариант без verbose\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "print(\"✅ Scheduler добавлен (ReduceLROnPlateau, совместимая версия)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659ce4c2-76d8-44c0-ba13-557aab9ce7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] train_loss=1.0273, acc=0.373 | val_loss=1.0966, acc=0.418 | lr=0.001000\n",
      "[2/5] train_loss=0.9628, acc=0.437 | val_loss=1.0389, acc=0.491 | lr=0.001000\n",
      "[3/5] train_loss=0.9599, acc=0.373 | val_loss=1.0888, acc=0.482 | lr=0.001000\n",
      "[4/5] train_loss=0.9470, acc=0.500 | val_loss=1.1519, acc=0.373 | lr=0.001000\n",
      "[5/5] train_loss=0.9615, acc=0.444 | val_loss=1.3215, acc=0.245 | lr=0.000500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss, running_acc, seen = 0.0, 0.0, 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        seg_out, cls_logits = model(xb)\n",
    "        loss = total_loss(cls_logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = accuracy(cls_logits, yb)\n",
    "        bs = yb.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        running_acc += acc * bs\n",
    "        seen += bs\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc = running_acc / seen\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device)\n",
    "\n",
    "    # обновляем scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"[{epoch}/{EPOCHS}] \"\n",
    "          f\"train_loss={train_loss:.4f}, acc={train_acc:.3f} | \"\n",
    "          f\"val_loss={val_loss:.4f}, acc={val_acc:.3f} | \"\n",
    "          f\"lr={optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f78287e-936e-4789-96f1-3a94662ad85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Модель сохранена по пути: E:\\work\\mvp_ultrasound\\models\\mvp_model.pt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "models_dir = Path(r\"E:\\work\\mvp_ultrasound\\models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "save_path = models_dir / \"mvp_model.pt\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"✅ Модель сохранена по пути: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01598d8b-34c8-41d9-9fbd-aed47f367389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
