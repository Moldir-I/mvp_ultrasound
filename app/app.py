import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
from torchvision import transforms
from pathlib import Path
import sys
import matplotlib.pyplot as plt

# === –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ (—á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å models/) ===
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.append(str(PROJECT_ROOT))

from models.hybrid_unet import HybridUNetClassifierClean  # –º–æ–¥–µ–ª—å

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
st.set_page_config(page_title="MVP Ultrasound", layout="centered")
st.title(" Ultrasound Brain Image Classifier (MVP)")
st.markdown("–ú–æ–¥–µ–ª—å: U-Net + Classifier ¬∑ –û–±—É—á–µ–Ω–∞ –Ω–∞ –£–ó–ò –≥–æ–ª–æ–≤–Ω–æ–≥–æ –º–æ–∑–≥–∞ —É –¥–µ—Ç–µ–π —Å –æ—Å–æ–±—ã–º–∏ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—è–º–∏")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
@st.cache_resource
def load_model():
    model = HybridUNetClassifierClean(num_classes=3)
    model_path = PROJECT_ROOT / "models" / "mvp_model.pt"
    state_dict = torch.load(model_path, map_location="cpu")
    missing, unexpected = model.load_state_dict(state_dict, strict=False)
    if missing:
        print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏:", missing)
    if unexpected:
        print("‚ö†Ô∏è –õ–∏—à–Ω–∏–µ –∫–ª—é—á–∏:", unexpected)
    model.eval()
    return model

try:
    model = load_model()
    st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
except Exception as e:
    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")

# === –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ===
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

label_names = ["benign", "malignant", "normal"]

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ ===
uploaded = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –£–ó–ò –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["png", "jpg", "jpeg"])

if uploaded is not None:
    image = Image.open(uploaded).convert("L")
    st.image(image, caption="–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏ –ø—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
    img_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        seg, logits = model(img_tensor)
        probs = torch.softmax(logits, dim=1).squeeze().numpy()
        pred_class = int(np.argmax(probs))
        mask = seg.squeeze().numpy()

    # === –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–∫–∏ ===
    mask = np.clip(mask, 0, 1)
    mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-6)
    mask = mask ** 3
    mask_bin = (mask > 0.6).astype(np.uint8) * 255

    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø–æ–¥ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    mask_img = Image.fromarray(mask_bin)
    mask_resized = mask_img.resize(image.size, resample=Image.BILINEAR)
    mask_resized = np.array(mask_resized, dtype=np.uint8)

    # === –ù–∞–ª–æ–∂–µ–Ω–∏–µ (–∫—Ä–∞—Å–Ω–∞—è –º–∞—Å–∫–∞ –ø–æ–≤–µ—Ä—Ö –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –£–ó–ò) ===
    overlay = np.array(image.convert("RGB"), dtype=np.uint8)
    mask_color = np.zeros_like(overlay, dtype=np.uint8)
    mask_color[..., 0] = mask_resized
    blended = cv2.addWeighted(overlay, 0.7, mask_color, 0.6, 0)

    # === –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
    st.markdown("## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("ü©ª *–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –¥–∏–∞–≥–Ω–æ–∑:*")
        st.subheader(f"{label_names[pred_class].capitalize()}")
    with col2:
        st.markdown("üìç *–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–Ω–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏):*")
        st.image(blended, caption="–°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±–ª–∞—Å—Ç—å", use_container_width=True)

    # === –î–∏–∞–≥—Ä–∞–º–º–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ ===
    st.markdown("### üîé –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º")

    # –¶–≤–µ—Ç–∞: –≤—ã–¥–µ–ª—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å —è—Ä–∫–æ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî —Å–µ—Ä–µ–µ
    colors = ["#6EC1E4", "#E74C3C", "#2ECC71"]  # –≥–æ–ª—É–±–æ–π, –∫—Ä–∞—Å–Ω—ã–π, –∑–µ–ª—ë–Ω—ã–π
    alpha = [0.3 if i != pred_class else 1.0 for i in range(len(label_names))]

    fig, ax = plt.subplots(figsize=(4, 2.8))
    for i, (label, p) in enumerate(zip(label_names, probs)):
        ax.bar(label, p * 100, color=colors[i], alpha=alpha[i])
        ax.text(i, p * 100 + 1, f"{p*100:.1f}%", ha='center', fontsize=10,
                fontweight='bold' if i == pred_class else 'normal')

    ax.set_ylim(0, 100)
    ax.set_ylabel("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (%)")
    ax.set_title("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤")
    st.pyplot(fig)

    # === –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å–∫–∏ ===
    with st.expander("üîç –ü–æ–∫–∞–∑–∞—Ç—å –º–∞—Å–∫—É –º–æ–¥–µ–ª–∏"):
        st.image(mask * 255, clamp=True, caption="–°—ã—Ä–∞—è –º–∞—Å–∫–∞ (–∏–∑ –º–æ–¥–µ–ª–∏)")